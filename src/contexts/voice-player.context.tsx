"use client"

import React, { createContext, useContext, useState, useRef, useCallback } from "react"
import type { TStateDirectMessage } from "@/utils/types/global"

// H√†m preload metadata c·ªßa audio v·ªõi fallback graceful
const preloadAudioMetadata = (url: string): Promise<number> => {
  return new Promise((resolve) => {
    const audio = new Audio()

    const handleLoadedMetadata = () => {
      const duration = audio.duration
      if (isFinite(duration) && duration > 0) {
        resolve(duration)
      } else {
        // Fallback: th·ª≠ seek ƒë·ªÉ trigger metadata loading
        audio.currentTime = 24 * 60 * 60 // Seek to 24 hours
        audio.addEventListener(
          "canplaythrough",
          () => {
            const seekedDuration = audio.duration
            if (isFinite(seekedDuration) && seekedDuration > 0) {
              resolve(seekedDuration)
            } else {
              // N·∫øu v·∫´n kh√¥ng load ƒë∆∞·ª£c, tr·∫£ v·ªÅ 0 ƒë·ªÉ hi·ªÉn th·ªã "--:--"
              console.warn("Could not load audio duration, using fallback")
              resolve(0)
            }
          },
          { once: true }
        )
        audio.addEventListener(
          "error",
          () => {
            console.warn("Audio metadata loading failed, using fallback")
            resolve(0)
          },
          { once: true }
        )
      }
    }

    const handleError = () => {
      console.warn("Audio loading failed, using fallback")
      resolve(0)
    }

    audio.addEventListener("loadedmetadata", handleLoadedMetadata, { once: true })
    audio.addEventListener("error", handleError, { once: true })

    audio.src = url
    audio.load()

    // Timeout fallback - kh√¥ng reject, ch·ªâ resolve v·ªõi 0
    setTimeout(() => {
      const timeoutDuration = audio.duration
      if (isFinite(timeoutDuration) && timeoutDuration > 0) {
        resolve(timeoutDuration)
      } else {
        console.warn("Audio metadata loading timeout, using fallback")
        resolve(0)
      }
    }, 5000)
  })
}

type VoicePlayerContextType = {
  // State
  isPlaying: boolean
  currentTime: number
  duration: number
  currentAudioUrl: string | null
  currentMessage: TStateDirectMessage | null
  playbackRate: number
  volume: number
  audioMessages: TStateDirectMessage[] // Danh s√°ch t·∫•t c·∫£ audio messages
  currentAudioIndex: number // V·ªã tr√≠ hi·ªán t·∫°i trong danh s√°ch

  // Actions
  playAudio: (message: TStateDirectMessage) => void
  pauseAudio: () => void
  seekAudio: (time: number) => void
  stopAudio: () => void
  setPlaybackRate: (rate: number) => void
  setVolume: (volume: number) => void
  playNext: () => void
  playPrevious: () => void
  setAudioMessages: (messages: TStateDirectMessage[]) => void

  // Player visibility
  showPlayer: boolean
  setShowPlayer: (show: boolean) => void
}

const VoicePlayerContext = createContext<VoicePlayerContextType | null>(null)

export const VoicePlayerProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [isPlaying, setIsPlaying] = useState(false)
  const [currentTime, setCurrentTime] = useState(0)
  const [duration, setDuration] = useState(0)
  const [currentAudioUrl, setCurrentAudioUrl] = useState<string | null>(null)
  const [currentMessage, setCurrentMessage] = useState<TStateDirectMessage | null>(null)
  const [showPlayer, setShowPlayer] = useState(false)
  const [playbackRate, setPlaybackRate] = useState(1)
  const [audioMessages, setAudioMessages] = useState<TStateDirectMessage[]>([])
  const [currentAudioIndex, setCurrentAudioIndex] = useState(0)
  const [volume, setVolume] = useState(1)

  const audioRef = useRef<HTMLAudioElement | null>(null)
  const lastPausedTimeRef = useRef<number>(0) // L∆∞u v·ªã tr√≠ khi pause

  const playAudio = useCallback(
    async (message: TStateDirectMessage) => {
      console.log("üéµ playAudio called with message:", message.id)

      if (!message.mediaUrl) {
        console.log("‚ùå No mediaUrl for message:", message.id)
        return
      }

      // C·∫≠p nh·∫≠t currentAudioIndex n·∫øu message c√≥ trong danh s√°ch
      const messageIndex = audioMessages.findIndex((msg) => msg.id === message.id)
      console.log(
        "üîç Message index in audioMessages:",
        messageIndex,
        "totalMessages:",
        audioMessages.length
      )

      if (messageIndex !== -1) {
        console.log("‚úÖ Found message in audioMessages, setting currentIndex:", messageIndex)
        setCurrentAudioIndex(messageIndex)
      } else {
        console.log("‚ö†Ô∏è Message not found in audioMessages, adding to end")
        // N·∫øu message kh√¥ng c√≥ trong danh s√°ch, th√™m v√†o cu·ªëi
        setAudioMessages((prev) => [...prev, message])
        setCurrentAudioIndex(audioMessages.length)
      }

      // N·∫øu ƒëang ph√°t audio kh√°c, d·ª´ng l·∫°i
      if (audioRef.current && currentAudioUrl !== message.mediaUrl) {
        audioRef.current.pause()
        audioRef.current.currentTime = 0
        lastPausedTimeRef.current = 0
      }

      setCurrentMessage(message)
      setCurrentAudioUrl(message.mediaUrl)
      setShowPlayer(true)

      // Preload metadata tr∆∞·ªõc
      const audioDuration = await preloadAudioMetadata(message.mediaUrl)
      setDuration(audioDuration)

      // T·∫°o audio element m·ªõi n·∫øu c·∫ßn
      if (!audioRef.current) {
        audioRef.current = new Audio()
      }

      // Remove event listeners c≈© ƒë·ªÉ tr√°nh duplicate
      audioRef.current.removeEventListener("loadedmetadata", () => {})
      audioRef.current.removeEventListener("timeupdate", () => {})
      audioRef.current.removeEventListener("ended", () => {})
      audioRef.current.removeEventListener("pause", () => {})
      audioRef.current.removeEventListener("play", () => {})

      audioRef.current.src = message.mediaUrl
      audioRef.current.playbackRate = playbackRate // √Åp d·ª•ng playback rate hi·ªán t·∫°i
      audioRef.current.volume = volume // √Åp d·ª•ng volume hi·ªán t·∫°i

      // N·∫øu l√† c√πng audio v√† ƒë√£ c√≥ v·ªã tr√≠ pause, ti·∫øp t·ª•c t·ª´ ƒë√≥
      if (currentAudioUrl === message.mediaUrl && lastPausedTimeRef.current > 0) {
        audioRef.current.currentTime = lastPausedTimeRef.current
        setCurrentTime(lastPausedTimeRef.current)
      } else {
        // Audio m·ªõi ho·∫∑c ch∆∞a c√≥ v·ªã tr√≠ pause, b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu
        audioRef.current.currentTime = 0
        setCurrentTime(0)
        lastPausedTimeRef.current = 0
      }

      // Event listeners
      const handleLoadedMetadata = () => {
        const loadedDuration = audioRef.current?.duration || 0
        // Ch·ªâ set duration n·∫øu preloaded duration kh√¥ng h·ª£p l·ªá
        if (!isFinite(audioDuration) || audioDuration <= 0) {
          setDuration(loadedDuration)
        }
      }

      const handleTimeUpdate = () => {
        const time = audioRef.current?.currentTime || 0
        setCurrentTime(time)
        // C·∫≠p nh·∫≠t v·ªã tr√≠ pause khi ƒëang ph√°t
        if (isPlaying) {
          lastPausedTimeRef.current = time
        }
      }

      const handleEnded = () => {
        setIsPlaying(false)
        setCurrentTime(0)
        lastPausedTimeRef.current = 0 // Reset khi k·∫øt th√∫c
      }

      const handlePause = () => {
        setIsPlaying(false)
        // L∆∞u v·ªã tr√≠ hi·ªán t·∫°i khi pause
        lastPausedTimeRef.current = audioRef.current?.currentTime || 0
      }

      const handlePlay = () => {
        setIsPlaying(true)
      }

      audioRef.current.addEventListener("loadedmetadata", handleLoadedMetadata)
      audioRef.current.addEventListener("timeupdate", handleTimeUpdate)
      audioRef.current.addEventListener("ended", handleEnded)
      audioRef.current.addEventListener("pause", handlePause)
      audioRef.current.addEventListener("play", handlePlay)

      // B·∫Øt ƒë·∫ßu ph√°t
      audioRef.current
        .play()
        .then(() => {
          setIsPlaying(true)
        })
        .catch((error) => {
          console.error("Error playing audio:", error)
        })
    },
    [currentAudioUrl, isPlaying, playbackRate, audioMessages, volume]
  )

  const pauseAudio = useCallback(() => {
    if (audioRef.current) {
      audioRef.current.pause()
      setIsPlaying(false)
      // L∆∞u v·ªã tr√≠ hi·ªán t·∫°i khi pause
      lastPausedTimeRef.current = audioRef.current.currentTime
    }
  }, [])

  const seekAudio = useCallback((time: number) => {
    if (audioRef.current) {
      audioRef.current.currentTime = time
      setCurrentTime(time)
      // C·∫≠p nh·∫≠t v·ªã tr√≠ pause khi seek
      lastPausedTimeRef.current = time
    }
  }, [])

  const stopAudio = useCallback(() => {
    if (audioRef.current) {
      audioRef.current.pause()
      audioRef.current.currentTime = 0
      setIsPlaying(false)
      setCurrentTime(0)
      setCurrentAudioUrl(null)
      setCurrentMessage(null)
      setShowPlayer(false)
      setDuration(0)
      lastPausedTimeRef.current = 0 // Reset khi stop
    }
  }, [])

  const handleSetPlaybackRate = useCallback((rate: number) => {
    if (audioRef.current) {
      audioRef.current.playbackRate = rate
      setPlaybackRate(rate)
    }
  }, [])

  const handleSetVolume = useCallback((volume: number) => {
    if (audioRef.current) {
      audioRef.current.volume = volume
      setVolume(volume)
    }
  }, [])

  const playNext = useCallback(() => {
    console.log(
      "‚è≠Ô∏è playNext called, currentIndex:",
      currentAudioIndex,
      "totalMessages:",
      audioMessages.length
    )

    if (currentAudioIndex < audioMessages.length - 1) {
      const nextIndex = currentAudioIndex + 1
      const nextMessage = audioMessages[nextIndex]
      console.log("‚è≠Ô∏è Playing next message:", nextMessage.id, "at index:", nextIndex)

      setCurrentAudioIndex(nextIndex)
      setCurrentMessage(nextMessage)
      setCurrentAudioUrl(nextMessage.mediaUrl ?? null)
      // T·ª± ƒë·ªông ph√°t audio ti·∫øp theo
      if (isPlaying) {
        playAudio(nextMessage)
      }
    } else {
      console.log("‚ùå Cannot play next: already at end")
    }
    // TODO: Trigger load more voices if needed
  }, [currentAudioIndex, audioMessages, isPlaying, playAudio])

  const playPrevious = useCallback(() => {
    console.log(
      "‚èÆÔ∏è playPrevious called, currentIndex:",
      currentAudioIndex,
      "totalMessages:",
      audioMessages.length
    )

    if (currentAudioIndex > 0) {
      const prevIndex = currentAudioIndex - 1
      const prevMessage = audioMessages[prevIndex]
      console.log("‚èÆÔ∏è Playing previous message:", prevMessage.id, "at index:", prevIndex)

      setCurrentAudioIndex(prevIndex)
      setCurrentMessage(prevMessage)
      setCurrentAudioUrl(prevMessage.mediaUrl ?? null)
      // T·ª± ƒë·ªông ph√°t audio tr∆∞·ªõc ƒë√≥
      if (isPlaying) {
        playAudio(prevMessage)
      }
    } else {
      console.log("‚ùå Cannot play previous: already at beginning")
    }
    // TODO: Trigger load more voices if needed
  }, [currentAudioIndex, audioMessages, isPlaying, playAudio])

  const handleSetAudioMessages = useCallback((messages: TStateDirectMessage[]) => {
    console.log("üéØ handleSetAudioMessages called with:", messages.length, "messages")
    console.log(
      "üéØ Messages:",
      messages.map((m) => ({ id: m.id, createdAt: m.createdAt }))
    )

    setAudioMessages(messages)
    setCurrentAudioIndex(0)
    setCurrentAudioUrl(messages[0]?.mediaUrl ?? null)

    console.log("‚úÖ Audio messages set in context, currentIndex:", 0)
  }, [])

  const value: VoicePlayerContextType = {
    isPlaying,
    currentTime,
    duration,
    currentAudioUrl,
    currentMessage,
    playbackRate,
    volume,
    audioMessages,
    currentAudioIndex,
    playAudio,
    pauseAudio,
    seekAudio,
    stopAudio,
    setPlaybackRate: handleSetPlaybackRate,
    setVolume: handleSetVolume,
    playNext,
    playPrevious,
    setAudioMessages: handleSetAudioMessages,
    showPlayer,
    setShowPlayer,
  }
  return <VoicePlayerContext.Provider value={value}>{children}</VoicePlayerContext.Provider>
}

export const useVoicePlayer = () => {
  const context = useContext(VoicePlayerContext)
  if (!context) {
    throw new Error("useVoicePlayer must be used within a VoicePlayerProvider")
  }
  return context
}
